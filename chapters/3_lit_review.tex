\chapter{Literature Review} 
\label{lit_review}

Recent advances in high performance computing have enabled the growth of the methods space in the areas of radiation transport and species transport. Problems which were previously considered to be computationally intractable to nuclear analysts can now be performed with modest computational resources. The goal of this chapter is to provide a survey of the open literature for the methods available to computing radiation transport, mobile depletion, and coupling these two phenomena together. The chapter begins by reviewing the numerical methods and open-source codes available for neutral particle transport with an emphasis placed on methods which are more applicable for computing radiation fields outside of a nuclear reactor core. This is followed by a review of methods used for mobile depletion and trace species transport. Finally, the various strategies that have been used to couple radiation transport and mobile depletion for the analysis of radiological hazards are discussed. Throughout this review, an emphasis is placed on discretization schemes which may be easily implemented in the \acrshort{moose} framework, including: \acrfull{fvm} schemes, \acrfull{dgfem} schemes, and \acrfull{cgfem} schemes.

\section{Neutral Particle Transport Methods for Ex-Core Applications}
\label{lit_review:radiation_transport}

The mathematical machinery required to describe the behavior of particles through a background medium was invented in 1872 by Ludwig Boltzmann and has found uses in various fields, from stellar astrophysics to nuclear reactor design \cite{transport_theory}. The governing equation is known as the Boltzmann transport equation; the solutions to which span three dimensions in space, two dimensions in direction, and one dimension each in energy and time. Owing to the complexity of this seven-dimensional phase space there are few analytical solutions to the transport equation, leading to a diverse array of computational methods to compute numerical solutions for engineering applications. These methods can be lumped into two categories: deterministic methods and stochastic methods. 

Stochastic methods, such as the Monte Carlo method avoid computing solutions to the transport equation directly and instead average the random walks of many individual particles through the problem phase space \cite{computational_methods}. This allows for a continuous treatment of each independent variable and is therefore the preferred approach when accuracy is paramount. The disadvantage of the Monte Carlo method is that many particle histories must be simulated when computing spatially-varying quantities such as particle fluxes, resulting in a substantial performance penalty for a required level of accuracy \cite{computational_methods}. This is further exacerbated in the cases of long particle streaming paths with large angle scattering, secondary particle production, and nuclear transmutations in structural materials. These challenges have largely prevented analog Monte Carlo simulations from being used for deep penetration problems without some form of variance reduction driven by a deterministic transport simulation (e.g. Forward-Weight Consistent Adjoint-Driven Importance Sampling \cite{fw_cadis,variance_reduction_review}) or iterative variance reduction (e.g. the Method of Automatic Generation of Importances by Calculation \cite{magic,variance_reduction_review}). Iterative variance reduction techniques require many iterations to converge spatially distributed quantities \cite{variance_reduction_review}, leading to the preferred use of deterministic transport method driven variance reduction methods or the use of deterministic transport methods over Monte Carlo methods for long length scale problems. 

Deterministic methods require each variable of the phase space be discretized resulting in a decrease in accuracy. When this is acceptable, deterministic methods prove to be advantageous as they require fewer computational resources to compute spatially varying quantities such as reaction rates \cite{applied_reactor_physics}. Individual deterministic transport methods have various advantages and disadvantages depending on the angular discretization scheme employed. This section discusses the major deterministic transport approaches which can be easily implemented in a finite element framework and major open-source radiation transport codes which may be integrated into the \acrshort{moose} framework.

\subsection{The Discrete Ordinates Method}
\label{lit_review:radiation_transport:s_n}

The \acrfull{sn} method is one of the most popular deterministic transport approaches owing to the generality of the method and the many performant solution algorithms that it enables. The \acrshort{sn} method draws discrete angular directions from an angular quadrature set, solving the multi-group transport equation along each discrete direction and computing source terms which require angular integrals with the chosen quadrature \cite{carlson_sn,computational_methods}. A typical application of the \acrshort{sn} method for fission reactor analysis is the generation of lattice parameters for full-core reactor physics calculations. In ex-core applications, the \acrshort{sn} method is used as either the main calculation method or to reduce the variance of Monte Carlo calculations. Examples include shutdown dose rate calculations for fusion reactors \cite{denovo_fusion,denovo_fusion_II} and modelling the neutron-gamma dose rate experience by fission reactor bioshields \cite{denovo_concrete}.

While the core fundamentals of the \acrshort{sn} method have not changed much since it was introduced to the nuclear industry by Carlson \cite{carlson_sn}, a substantial amount of work has been performed to determine spatial discretization schemes which enhance the \acrshort{sn} method and enable efficient solution algorithms. Discontinuous spatial discretization methods in space (where jump discontinuities are allowed between neighboring mesh elements) are often preferred as they result in a block-triangular matrix structure within each direction. These matricies may be inverted without needing to assemble the full system of equations through the use of a transport sweep (equivalent to forward or backward substitution), a signature advantage of the \acrshort{sn} method \cite{massively_parallel_sweeps,computational_methods}. The most popular discontinuous discretization approaches is the \acrshort{dgfem} \cite{schunert_sn_discretization,dgfem_1}. \acrshort{dgfem} methods require the storage of a greater number of unknowns compared to other discontinuous methods such as diamond differencing, are less likely to yield negative fluxes when used with the \acrshort{sn} equations, and are easier to generalize to unstructured meshes. 

Although discontinuous methods remain the preferred choice for discretizing the \acrshort{sn} equations, there are several approaches which use the \acrshort{cgfem} which prove to be advantageous for implementation in multiphysics frameworks as most other physics require the use of the \acrshort{cgfem}. These approaches use second order transport methods, by which the multi-group transport equation is manipulated such that the first derivatives in the streaming term become second derivatives \cite{computational_methods}. This includes the the even-parity transport equation \cite{computational_methods}, odd-parity transport equation \cite{computational_methods}, the \acrfull{saaf} equation \cite{cgfem_saaf_1,cgfem_saaf_sn_2,cgfem_saaf_sn_3}, and least-squares equation \cite{cgfem_ls_sn_1,cgfem_ls_sn_2}. The even-parity and odd-parity transport equations have largely fallen out of favour for the \acrshort{saaf} and least-squares equations due to the need to reconstruct scalar fluxes and particle currents from the even/odd parity angular fluxes \cite{computational_methods}. The least-squares approach has the advantage of generating a symmetric positive-definite system of equations while not resulting in singularities in regions with near-zero cross sections \cite{cgfem_ls_sn_1,cgfem_ls_sn_2}. The former is essential when using efficient matrix solution schemes such as the conjugate gradient method \cite{cgfem_ls_sn_1,cgfem_ls_sn_2}. A disadvantage of the least-squares equation is the lack of global conservation \cite{cgfem_ls_sn_1,cgfem_ls_sn_2}; particle balances are not conserved on a per-cell basis or across the entire domain. The least-squares equations also lack causality \cite{cgfem_ls_sn_2}; local changes in the solution numerically propagate against the direction of particle travel to modify the upwind solution. The \acrshort{saaf} scheme is advantageous over the least-squares method as it maintains global particle conservation. The main disadvantage of the \acrshort{saaf} approach is that it is poorly posed in regions with cross sections that are close to zero \cite{cgfem_saaf_1,cgfem_saaf_sn_2,cgfem_saaf_sn_3}. This can be mitigated by applying \acrfull{supg} stabilization in near-void regions \cite{cgfem_saaf_sn_2}, however this removes the symmetry in the resulting discretized system of equations. Each \acrshort{cgfem} method discussed above requires the assembly of a large sparse matrix per-direction, resulting in a large memory and computing time cost when compared to \acrshort{dgfem} methods with matrix-free transport sweeps. However, this downside is mitigated when transport sweeps cannot be easily implemented as a full matrix assembly of the \acrshort{sn} equations discretized with the \acrshort{dgfem} requires more memory then \acrshort{cgfem}s. The \acrshort{cgfem} approaches are also more susceptible to oscillations around strong material discontinuities when compared to the \acrshort{dgfem}.

Even though the \acrshort{sn} method has several performance advantages, it has a major disadvantage in the form of ray-effects \cite{computational_methods}. Ray effects are caused by the limited angular resolution of \acrshort{sn} transport calculations in regions which are optically thin. These non-physical oscillations occur in the presence of localized particle sources, and are remarkably difficult to remove by refining the angular quadrature set thereby requiring some form of mitigation. There are several approaches for mitigating ray effects in \acrshort{sn} transport solvers. The most common of these approaches is to split the flux into an uncollided and collided component. The uncollided component is solved with a technique which does not exhibit ray effects such as Monte Carlo methods \cite{denovo} or integral transport methods \cite{harbour_uncollided,fem_arbitrary_uncollided}. The \acrshort{sn} solver is then used to solve for the collided component using the uncollided flux from the previous step for all relevant sources in the multi-group transport equation, and the results are added together to yield a solution with ray effects mitigated. Methods other then flux splitting include \acrshort{pn} fictitious source methods \cite{anal_ray_effect_mitigation, 2D_ray_effect_mitigation} and finite element methods in angle \cite{anal_ray_effect_mitigation}. These alternative methods have largely fallen out of favour due to the ease of implementation of flux splitting and the effectiveness of the approach. 

The dominant method for computing the uncollided flux required by flux splitting is the method of ray tracing (an integral transport method), where the external particle sources is discretized using a spatial quadrature and the flux is computed semi-analytically by tracing rays from each quadrature point to each other point in the spatial domain \cite{harbour_uncollided,fem_arbitrary_uncollided}. The main benefit of ray tracing is that it is exact for point sources, and so sources of error are the result of the spatial quadrature used and the basis functions of the target element. However, these sources of error prevent ray tracing from being either globally or locally conservative unless additional measures are taken. This includes the use of scaling factors on the computed uncollided flux to fix global conservatism \cite{attila_uncollided} or tracing rays to element faces and computing particle currents to enforce local conservatism \cite{ardra_uncollided}. A new approach to compute the uncollided flux been proposed by Shands, Hanopy, and Morel which collapses the angular domain of the multi-group transport equation into the spatial domain, yielding a series of S\textsubscript{2}-like equations \cite{modified_sn}. This technique avoids ray tracing over the majority of the computational domain, thereby avoiding the load balancing issues and nonlinear scaling of the ray densities which result in performance penalties that are inherit to ray tracing \cite{fem_arbitrary_uncollided,modified_sn}. 

\subsection{Spherical Harmonics Methods}
\label{lit_review:radiation_transport:p_n}

The \acrfull{pn} scheme is another approach taken to discretize the transport equation in angle which was initially used by astrophysicists to study light transport in stellar objects \cite{applied_reactor_physics}, and is therefore suited to ex-core transport applications. This approach approximates the angular dependence of the angular flux with a finite expansion in the real spherical harmonics, and has shown a major advantage over the \acrshort{sn} method in that it is immune to ray effects. However, the method is susceptible to another class of artifacts. These are known as the Gibbs phenomena; they occur due to the approximation of a discontinuous function in angle (the angular flux) with smooth basis functions \cite{pn_2,pn_3} and disappear as the order of the spherical harmonics approximation is increased. The Gibbs phenomena are particularly severe near large jump discontinuities in material properties and get advected by the \acrshort{pn} equations through free space, resulting in a non-local impact on the solution accuracy. These artifacts can be mitigated through the implementation of a filter which dampens the amplitude of the oscillations near regions that have strongly discontinuous material properties or are near-void \cite{pn_1,pn_2,pn_3}.

As with the \acrshort{sn} equations, the \acrshort{pn} equations have several options for discretization schemes. The \acrshort{dgfem} has proven to be the most popular scheme for the \acrshort{pn} equations \cite{pn_2,dgfem_pn_1,laboure_pn_discretization} for similar reasons as it is preferred for the \acrshort{sn} equations: discontinuous basis functions yield better approximations near material discontinuities, robustness in regions with low cross sections, and reasonable performance in the diffusion limit. However, there are alternative discretizations which use the \acrshort{cgfem} and second order forms of the \acrshort{pn} equations. These include the \acrshort{saaf} equations \cite{cgfem_saaf_1,laboure_pn_discretization} and least-squares equations \cite{laboure_pn_discretization,cgfem_ls_saaf_pn}. These discretization schemes have many of the same disadvantages as \acrshort{cgfem}s applied to the \acrshort{sn} equations; namely that of oscillatory behavior near strong material discontinuities. As the system of equations generated by \acrshort{pn} methods cannot be solved with matrix free methods (unlike the \acrshort{sn} equations) when discretized with \acrshort{dgfem}, \acrshort{cgfem} discretizations schemes have an advantage in memory usage over their discontinuous counterparts. This is caused by the need to store interfacing angular unknowns in \acrshort{dgfem} methods which are not required with \acrshort{cgfem} discretization approaches.  

\subsection{Open-Source Radiation Transport Codes}
\label{lit_review:radiation_transport:codes}

While there are many neutron/photon transport codes discussed in the open literature utilizing \acrshort{pn} or \acrshort{sn} methods, the vast majority of these codes are export controlled. This makes their integration into \texttt{Caribou} intractable as \texttt{Caribou} aims to be open-sourced upon its completion. This limits possible code integration options to open-source radiation transport solvers. The most notable of these solvers include \texttt{OpenMC} \cite{openmc}, \texttt{Cardinal} \cite{cardinal}, OpenMOC \cite{openmoc}, and \texttt{Chi-Tech} \cite{massively_parallel_sweeps}.

\texttt{OpenMC} is an incredibly popular Monte Carlo neutron/photon transport solver which remains under active development by multiple organizations. \texttt{OpenMC} contains routines for criticality calculations, fixed source problems, radionuclide depletion, and nuclear heating. While the list of capabilities contained in \texttt{OpenMC} is expansive for reactor physics applications, it lacks capabilities which allow it to be used for practical shielding calculations within a Monte Carlo framework. These necessary capabilities include radionuclide particle sources and explicit variance reduction \cite{openmc}. \texttt{Cardinal} is an open-source wrapping of \texttt{OpenMC} in the \acrshort{moose} framework which automatically performs in-memory transfers between the constructive solid geometry used by \texttt{OpenMC} and the finite element mesh used by \acrshort{moose}. As \texttt{Cardinal} is a wrapper application it inherits all of the advantages and disadvantages of \texttt{OpenMC} \cite{cardinal}.

\texttt{OpenMOC} is a reactor physics application under development at Massachusetts Institute of Technology \cite{openmoc} designed for full-core reactor analysis using the \acrfull{moc}. The \acrshort{moc} converts the multi-group transport equation to a characteristic form where the angular variables are then discretized with the \acrshort{sn} method and the spatial variables are treated using ray tracing \cite{applied_reactor_physics}. This nets two main benefits: it allows for the use of constructive solid geometry and so no errors are introduced in the geometry itself, and it allows the change in angular flux to be computed across each region analytically. To make this possible the behavior of the particle source must be assumed, these assumptions are either the flat source assumption or the linear source assumption; both of which are implemented in \texttt{OpenMOC} \cite{openmoc,gunow_linear_moc}. The flat and linear source assumptions necessitate that spatial regions be subdivided to decrease the impact of the spatial errors, not unlike the need to refine a mesh in a finite element simulation. The practical implication of this subdivision is that many more rays must be tracked over the computational domain if well-refine spatial quantities are required, making \acrshort{moc} methods unsuited for ex-core shielding calculations. \acrshort{moc} methods prove to be useful in a fission reactor multiphysics setting where they provide surface radiation sources used for ex-core radiation transport \cite{denovo_concrete}.

\texttt{Chi-Tech} is a massively parallel \acrshort{sn} neutral particle transport solver under development at Texas A\&M University designed for performing fixed source and criticality calculations, along with coupling with other codes in a multiphysics setting \cite{massively_parallel_sweeps}. \texttt{Chi-Tech} discretizes the transport equation in space using the \acrshort{dgfem}, implements several layers of acceleration schemes alongside an asynchronous parallel transport sweeper, and contains multiple ray effect mitigation strategies \cite{modified_sn}. The main disadvantage of \texttt{Chi-Tech} is the inability to perform mixed photon-neutron modelling for shielding analysis and a lack of radionuclide sources. Otherwise, it is well suited for ex-core radiation transport calculations.

\section{Trace Species Transport}
\label{lit_review:mass_transport}

Trace species transport is concerned with the evolution of a passive scalar quantity as it is advected along a fluid; considered a valid approximation when the mass fraction of the trace species relative to the fluid is sufficiently low \cite{turbulent_species_transport}. Trace species transport is used to study the advection of precursors and other transmutation products in \acrshort{msr}s \cite{moltres,moose_ns_crab}, investigate the evolution of various reacting gases which occur in containment buildings during accident scenarios \cite{containment_foam}, and simulate the transport of activation products in thermonuclear fusion reactor cooling systems \cite{fusion_activation_wall,fusion_activation_tool_fluned,fusion_activation_demo_wcll,fusion_activation_modelling}.

There are two main approaches for computationally evaluating trace species transport. The first is the Lagrangian particle tracking method, where the trace species is approximated with many individual particles. A momentum equation in ordinary differential equation form is time integrated for each particle which considers various forces, such as gravity, drag, and shear induced lift from the fluid \cite{turbulent_species_transport}. At the end of each time step, the location of the particles are used to compute normalized average values of interest. Lagrangian particle tracking gained popularity by being easy to implement and trivial to extend to parallel computing. However, Lagrangian particle tracking faces a similar problem to that of Monte Carlo radiation transport: if spatially varying quantities such as the particle concentration are required the number of particles must be increased drastically to gain statistically meaningful results \cite{turbulent_species_transport}. The second approach for trace species transport is the Eulerian approach, where the trace species are approximated to be a series of continuous scalar fields governed by an accompanying advection-diffusion-reaction equation. This approach gained popularity due to its performance benefits, with the downside that turbulence modelling and associated closure problems must be considered \cite{turbulent_species_transport}.

Several methods exist for the spatial discretizations of the Eulerian species transport equations, the most popular of these approaches is the \acrshort{fvm} \cite{finite_volume_methods,moose_ns_crab}. The \acrshort{fvm} is a discontinuous approach which integrates the species transport equations over a single finite volume, applies Gauss's theorem to convert the advection and diffusion terms to surface integrals, and then approximates variable values on surfaces with a closure relationship. The \acrshort{fvm} with an appropriate closure relationship proves to be advantageous as it demonstrates local conservation and prevents the vast majority of negative values in numerical solutions \cite{finite_volume_methods,moose_ns_crab}. The main disadvantages of the \acrshort{fvm} is that the scheme is only capable of storing element-centered values of species concentration, leading to highly discontinuous solutions when a coarse mesh is used. Another discretization method for the trace species equations is the \acrshort{cgfem} using \acrshort{supg} stabilization. This method modifies the test functions used in the \acrshort{cgfem} to include a stabilization parameter which selectively applies diffusion in an upwind direction \cite{ns_supg, ad_diff_supg}. The main benefit of \acrshort{supg} stabilization for continuous finite elements over the \acrshort{fvm} is the increased accuracy and ability to generate a continuous solution field for coupled multiphysics. \acrshort{cgfem} schemes show oscillatory behavior when advecting over a highly discontinuous velocity field \cite{moose_ns_cgfem}. 

\section{Coupling Radiation Transport and Mobile Depletion}
\label{lit_review:multiphysics}

Interest in coupling radiation transport with mobile depletion to determine the spatially distributed concentration of radioactive effluents has been fairly recent, likely owing to recent advances in high-performance computing. This interest is driven by the fusion community due to the sensitivity of fusion reactor components to radiation fields \cite{fusion_activation_wall,fusion_activation_tool_fluned,fusion_activation_demo_wcll,fusion_activation_modelling} and the \acrshort{msr} community due to the liquid fuel \cite{scale_msr,griffin_pronghorn_msr_init,griffin_pronghorn_msr} used by this Generation IV reactor. This section provides an overview of the methods used in the nuclear industry to compute highly mobile radioactive source term, including recent advances and historical methods.

The vast majority of the previous work surrounding the computation of mobile radionuclide effluents is low fidelity, either using a single computed value of the neutron flux or source term combined with control volume modelling. Hoq et al. \cite{ar41_triga_2} uses a series of control volumes to discretize the reactor building and primary systems of a TRIGA reactor. This analytical model is provided with an $\mathrm{^{41}Ar}$ source term computed using a chosen value of a thermal neutron flux an $\mathrm{^{40}Ar}$ to $\mathrm{^{41}Ar}$ transmutation cross section, allowing for a release prediction. The predicted stack outlet concentration varied by an order of magnitude from the measured release \cite{ar41_triga_2}. Similar to Hog et al., Veluri et al. \cite{ar41_etc_hfrr} combines a predetermined radionuclide source with a control volume model of the primary coolant system of a novel pool-type research reactor. This was used to model the transport of various activation products ($\mathrm{^{25}Na}$, $\mathrm{^{27}Mg}$, $\mathrm{^{28}Al}$ and $\mathrm{^{41}Ar}$) for the purpose of evaluating the effectiveness of purification flow for reducing the dose at the surface of the pool. Guo et al. \cite{activation_coolant_ap1000} model an AP1000 primary heat transport system using both a homogeneous (one control volume) and two control volume approach. The authors used fewer subdivisions of the primary circuit than the works of Hog et al. and Veluri et al.. This work differs in that a 172 group core average neutron flux is used for computing the concentrations of coolant activation products ($\mathrm{^{16}N}$, $\mathrm{^{17}N}$, $\mathrm{^{3}H}$ and $\mathrm{^{14}C}$), recognizing the importance of spectral effects to neutron transmutation. Both control volume approaches resulted in large under predictions of activation products when compared to AP1000 operating data, with the two-volume approach performing better than the homogeneous approach for short-lived nuclides \cite{activation_coolant_ap1000}.

In contrast to the methods discussed above, several works use higher fidelity neutronics models for computing the activation source term. Mladin et al. \cite{ar41_triga_1} uses a TRIGA reactor model in MCNP to tally the production of $\mathrm{^{41}Ar}$ in the primary coolant, adding a spatial and energy dependence to the calculated source term. This source term was then passed to a nodalized facility model of the TRIGA reactor hall, allowing for the calculation of $\mathrm{^{41}Ar}$ transport to its eventual release. The calculated $\mathrm{^{41}Ar}$ emission rate and measured emission rates from the stack in the TRIGA facility were found to be in good agreement \cite{ar41_triga_1}. Žohar and Snoj \cite{activation_coolant_fission_fusion} model a typical pressurized water reactor in MCNP. This model is then split into four different zones (downcomer, lower plenum, core, and upper plenum) where the transmutation reaction rates of $\mathrm{^{16}N}$, $\mathrm{^{17}N}$, and $\mathrm{^{19}O}$ are tallied independently in each region. The core primary circuit was then modelled with a control volume approach to determine the time to equilibrium activity for each radionuclide species and the resulting activities in a steam generator \cite{activation_coolant_fission_fusion}.

Owing to the liquid fuel used by this Generation IV reactor, the \acrshort{msr} community is substantially more active in coupling radiation transport with mobile depletion. There are specific constraints on mobile depletion in \acrshort{msr}s which make the simulation of a full depletion chain with advection terms impractical, namely the long time scales of reactor dynamics and the large number of nuclides required (greater than 2,000) to accurately predict reactor dynamics over time scales which span several orders of magnitude \cite{griffin_pronghorn_msr}. The \texttt{SCALE} code suite includes the ability to add nuclide addition and removal rates to depletion calculations to individual control volumes within an \acrshort{msr} \cite{scale_msr}. Removal rates are implemented in the form of removal half-lives which are calculated based on the amount of time required for an amount of the fuel salt to transfer from one control volume to the next control volume. A similar capability was initially implemented in \texttt{Griffin} \cite{griffin_pronghorn_msr_init} and was found to be inadequate for predicting the behavior of transients in \acrshort{msr}s \cite{griffin_pronghorn_msr}. \texttt{Griffin} now couples with \texttt{Pronghorn} to enable a three stage approach which separates nuclides into bins depending on the half-lives associated with each nuclide. Short lived nuclides are assumed to decay in-place such that they do not have a chance to be advected through the core. Medium lived nuclides are advected through the core by \texttt{Pronghorn} while undergoing depletion until they reach steady-state. The spatial distribution of long-lived nuclides is assumed to be independent of the temporal distribution once the \acrshort{msr} reaches steady state. This allows for the application of static depletion solvers to evolve the distribution of long lived nuclides in time while computing the spatial distribution with a steady-state thermal-hydraulics solve with \texttt{Pronghorn} \cite{griffin_pronghorn_msr}.

Compared to the non-\acrshort{msr} fission reactor analysis space, the fusion reactor community is far more active in developing methods to predict the spatial distribution of highly mobile radionuclides. Nobs et al. \cite{fusion_activation_wall} simulate the production of $\mathrm{^{16}N}$ in an experimental mockup of an ITER first wall component with a water cooling system. MCNP and FISPACT-II were used to evaluate the spatial distribution of $\mathrm{^{16}N}$ in the water cooling system using a distributed tally. The activity distribution was provided to GammaFlow, a 1D systems level trace species transport code used to evaluate activity distributions in fusion reactor cooling systems. It was found that the predictions agreed reasonably well with an equivalent experiment, with GammaFlow consistently under-predicting the activity in the CsI detector tank \cite{fusion_activation_wall}. Chiovaro et al. \cite{fusion_activation_demo_wcll} performs a similar analysis on a water-cooled breeding blanket using MCNP for determining $\mathrm{^{16}N}$ and $\mathrm{^{17}N}$ concentrations. ANSYS CFX was used to assess 3D trace species transport within the water cooling channels of the blanket given a distributed source from MCNP. Carrero, Cau and Pampin \cite{fusion_activation_modelling} improve on the work of Nobs et al. \cite{fusion_activation_wall} by developing a high-fidelity trace species transport model using passive scalars in ANSYS Fluent. This was driven by $\mathrm{^{16}N}$ and $\mathrm{^{17}N}$ average and distributed sources determined in previous works. Verification studies against Nobs et al. \cite{fusion_activation_wall} demonstrated in agreement with the previous approach, and the analysis was extended to full wall components. These analysis showed that distributed activation field are required when considering more complicated transport models. Pietri et al. \cite{fusion_activation_tool_fluned} unifies the previously discussed methods by developing a trace species transport solver called FLUNED in OpenFOAM which takes an activation source from D1SUNED, an extension of MCNP. The solver was validated against the work of Nobs et al. \cite{fusion_activation_wall}, finding good agreement in predicting the decay of $\mathrm{^{16}N}$ in the fluid detector and reasonable agreement in the prediction of the decay of $\mathrm{^{17}N}$ (when experimental and cross section uncertainties are considered).

Therefore, radiation transport and mobile depletion have found several applications in both the fission reactor and fusion reactor space for computing mobile radioactive effluents. The addition of these capabilities to \texttt{Caribou} would make performing these analyses substantially easier, enabling a multi-scale framework for environmental impact assessment and radiation protection starting from within the containment system.  

\section{Summary and Selection of Methods}
\label{lit_review:summary}

While there are several candidate open-source radiation transport codes, none of them meet the functional requirements set out by \texttt{Caribou}. Both \texttt{OpenMC} and \texttt{Cardinal} lack the variance reduction capabilities required for performing long length scale radiation transport calculations. \texttt{OpenMOC}, and the \acrshort{moc} scales poorly to long length scales due to the large number of rays required for a given solution resolution. \texttt{Chi-Tech} would be an ideal candidate for integration into \texttt{Caribou}. However, the lack of radionuclide sources and a dedicated depletion solver makes it unsuited for coupled neutron-gamma shielding problems which \texttt{Caribou} aims to include in its capability suite. These findings motivate the development of a new radiation transport solver for \texttt{Caribou}.

When selecting a discretization approach for the transport equation both the performance of the scheme and its accuracy are paramount. The \acrshort{pn} equations couple all spherical harmonics moments of the flux together through the streaming operator, necessitating a single monolithic solver. The \acrshort{sn} equations only couple each direction together through the scattering operator, allowing for the use of powerful iterative techniques such as scattering source iteration. Even if the \acrshort{cgfem} is used over the \acrshort{dgfem}, these iterative procedures allow the \acrshort{sn} equations to be more computationally efficient then the \acrshort{pn} method. When it comes to the numerical disadvantages of each approach, ray effect mitigation measures prove to be a one-shot solution which allows the use of a low-order angular quadrature set. \acrshort{pn} filtering still requires substantially more angular moments then required by the scattering expansion. Based on this comparison, this work elects to implement a \acrshort{sn} transport solver. With the angular method chosen, all that remains is to chose a spatial discretization scheme. The \acrshort{dgfem} has become the standard approach for differencing the transport equation, however it requires the implementation of a transport sweeper to avoid the memory penalty due to the need to store interface angular fluxes. Given that \acrshort{moose} supports arbitrary polyhedral meshes, the implementation of an efficient massively parallel sweeper \cite{massively_parallel_sweeps} would be challenging and so it was decided that a \acrshort{cgfem} discretization scheme would be chosen instead. Out of the options for second order transport, the \acrshort{saaf} method is preferred over the least-squares equations due to the preservation of global conservatism and causality. 

There are advantages and disadvantages of both the Lagrangian and Eulerian approach to computing trace species transport. As this work considers the activation of trace species in fluids, the underlying concentration fields for each nuclide must be known with confidence. This would require the simulation of a prohibitively large number of particles for each nuclide in order to resolve depletion, which is computationally intense compared to the Eulerian approach. Therefore, this work chooses to implement an Eulerian trace species transport solver for mobile depletion. When it comes to the discretization scheme to implement, the \acrshort{moose} \texttt{NavierStokes} module supports both \acrshort{fvm} and \acrshort{supg} discretization schemes for fluids and trace species transport \cite{moose_ns_summary}. To maximize compatibility with the fluids package built in \acrshort{moose}, both spatial discretization schemes will be adopted.